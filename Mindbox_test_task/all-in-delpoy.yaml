# ==========================================================
# Namespace для приложения
# ==========================================================
apiVersion: v1
kind: Namespace
metadata:
  name: test-task
  labels:
    name: test-task
---
# ==========================================================
# Service (ClusterIP)
# ==========================================================
apiVersion: v1
kind: Service
metadata:
  name: app
  namespace: test-task
  labels:
    app: app
spec:
  selector:
    app: app                # связываем с подами по label
  ports:
    - port: 80              # сервис слушает на 80 порту
      targetPort: 8080      # контейнеры слушают внутри на 8080
      protocol: TCP
  type: ClusterIP           # доступен только внутри кластера
---
# ==========================================================
# Deployment — манифест приложения
# ==========================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
  namespace: test-task
  labels:
    app: app
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0     # всегда держим все реплики живыми во время обновления
      maxSurge: 1           # увеличение на 1 под
  selector:
    matchLabels:
      app: app              # связываем с подами
  template:
    metadata:
      labels:
        app: app
    spec:
      terminationGracePeriodSeconds: 30   # время на корректное завершение работы
      # Распределение подов по зонам и нодам для отказоустойчивости
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone  # равномерное распределение по зонам
          whenUnsatisfiable: ScheduleAnyway          # если нельзя — всё равно запускаем
          labelSelector:
            matchLabels:
              app: app
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname       # равномерное распределение по нодам
          whenUnsatisfiable: ScheduleAnyway
          labelSelector:
            matchLabels:
              app: app
      containers:
        - name: app
          image: test.registry.local/app:latest   # берем последний образ приложения
          ports:
            - containerPort: 8080
          resources:
            # Requests — гарантированные ресурсы (используются для HPA)
            requests:
              cpu: "50m"      # 0.05 CPU — приложение в среднем использует очень мало
              memory: "128Mi" # память всегда стабильна
            # Limits — максимум, что под может использовать
            limits:
              cpu: "500m"     # запас на скачок при инициализации
              memory: "256Mi"
          # StartupProbe — проверка на запуск (учитываем долгий старт 5–10 сек)
          startupProbe:
            httpGet:
              path: /health/startup
              port: 8080
            periodSeconds: 3
            failureThreshold: 5   # максимум ~15 сек на старт
          # ReadinessProbe — проверка, что под готов принимать трафик
          readinessProbe:
            httpGet:
              path: /health/ready
              port: 8080
            periodSeconds: 5
            timeoutSeconds: 2
            failureThreshold: 3   # проверка на доступность
          # LivenessProbe — проверка, что приложение не зависло
          livenessProbe:
            httpGet:
              path: /health/live
              port: 8080
            initialDelaySeconds: 20  # ждём перед первой проверкой
            periodSeconds: 10
          # PreStop hook — даём 5 секунд перед завершением, чтобы запросы успели обработаться
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5"]
---
# ==========================================================
# HorizontalPodAutoscaler — авто-масштабирование подов
# ==========================================================
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
  namespace: test-task
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app
  minReplicas: 1              # ночью остаётся 1 под
  maxReplicas: 6              # днём масштабируемся до 6 подов, с запасом на всякий случай
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70   # 70% от request (50m) = ~35m
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60   # не масштабируемся слишком резко
      policies:
        - type: Percent
          value: 100                   # максимум удвоение за раз
          periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 минут, чтобы не схлопываться резко
      policies:
        - type: Percent
          value: 50                    # максимум минус половина за раз
          periodSeconds: 60
---
# ==========================================================
# PodDisruptionBudget — гарантирует, что всегда доступны >=2 пода
# ==========================================================
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: app-pdb
  namespace: test-task
spec:
  selector:
    matchLabels:
      app: app
  minAvailable: 2
---
# ==========================================================
# Ingress — точка входа снаружи (через Ingress Controller)
# ==========================================================
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  namespace: test-task
spec:
  ingressClassName: nginx
  rules:
    - host: app.test.local   # заменить на реальный домен
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: app
                port:
                  number: 80  